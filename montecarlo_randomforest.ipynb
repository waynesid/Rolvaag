{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "#load the team related datasets into the notebook and save them as dataframes\n",
    "def country_df(csv):\n",
    "  df = pd.read_csv(csv)\n",
    "  df.sort_values('HomeTeam', inplace=True)\n",
    "  df.reset_index(inplace=True)\n",
    "  df.drop(\"index\", axis =1 , inplace=True)\n",
    "\n",
    "  return df\n",
    "\n",
    "df_france = country_df('FootballData/F1.csv')\n",
    "df_spain  = country_df('FootballData/SP1.csv')\n",
    "df_england  = country_df('FootballData/E0.csv')\n",
    "df_championship  = country_df('FootballData/E1.csv')\n",
    "#df_finland  = country_df('/content/drive/MyDrive/FootballData/FIN.csv')\n",
    "#df_germany = country_df('FootballData/D1.csv')\n",
    "df_england_22 = country_df('FootballData/E0_22.csv')\n",
    "df_spa_22 = country_df('FootballData/SP1_22.csv')\n",
    "#df_jpn = country_df('FootballData/JPN.csv')\n",
    "df_ita = country_df('FootballData/I1.csv')\n",
    "df_E1 = country_df('FootballData/E1.csv')\n",
    "df_E2 = country_df('FootballData/E2.csv')\n",
    "df_E3 = country_df('FootballData/E3.csv')\n",
    "df_EC = country_df('FootballData/EC.csv')\n",
    "df_F2 = country_df('FootballData/F2.csv')\n",
    "df_I2 = country_df('FootballData/I2.csv')\n",
    "df_dataE0 = country_df('FootballData/data (9)/E0.csv')\n",
    "df_dataE1 = country_df('FootballData/data (9)/E1.csv')\n",
    "df_dataE2 = country_df('FootballData/data (9)/E2.csv')\n",
    "df_dataE3 = country_df('FootballData/data (9)/E3.csv')\n",
    "df_dataEC = country_df('FootballData/data (9)/EC.csv')\n",
    "df_dataF2 = country_df('FootballData/data (9)/F2.csv')\n",
    "df_dataG1 = country_df('FootballData/data (9)/G1.csv')\n",
    "df_dataN1 = country_df('FootballData/data (9)/N1.csv')\n",
    "df_dataP1 = country_df('FootballData/data (9)/P1.csv')\n",
    "df_dataSC0 = country_df('FootballData/data (9)/SC0.csv')\n",
    "df_dataSC1 = country_df('FootballData/data (9)/SC1.csv')\n",
    "df_dataSC2 = country_df('FootballData/data (9)/SC2.csv')\n",
    "df_dataSC3 = country_df('FootballData/data (9)/SC3.csv')\n",
    "df_dataSP2 = country_df('FootballData/data (9)/SP2.csv')\n",
    "df_dataSP1 = country_df('FootballData/data (9)/SP1.csv')\n",
    "df_dataT1 = country_df('FootballData/data (9)/T1.csv')\n",
    "\n",
    "df_data8E0 = country_df('FootballData/data (8)/E0.csv')\n",
    "df_data8E1 = country_df('FootballData/data (8)/E1.csv')\n",
    "df_data8E2 = country_df('FootballData/data (8)/E2.csv')\n",
    "df_data8E3 = country_df('FootballData/data (8)/E3.csv')\n",
    "df_data8EC = country_df('FootballData/data (8)/EC.csv')\n",
    "#df_data8F2 = country_df('FootballData/data (8)/F2.csv')\n",
    "df_data8G1 = country_df('FootballData/data (8)/G1.csv')\n",
    "#df_data8N1 = country_df('FootballData/data (8)/N1.csv')\n",
    "#df_data8P1 = country_df('FootballData/data (8)/P1.csv')\n",
    "df_data8SC0 = country_df('FootballData/data (8)/SC0.csv')\n",
    "df_data8SC1 = country_df('FootballData/data (8)/SC1.csv')\n",
    "df_data8SC2 = country_df('FootballData/data (8)/SC2.csv')\n",
    "df_data8SC3 = country_df('FootballData/data (8)/SC3.csv')\n",
    "#df_data8SP2 = country_df('FootballData/data (8)/SP2.csv')\n",
    "df_data8SP1 = country_df('FootballData/data (8)/SP1.csv')\n",
    "df_data8T1 = country_df('FootballData/data (8)/T1.csv')\n",
    "\n",
    "\n",
    "df_data7E0 = country_df('FootballData/data (7)/E0.csv')\n",
    "df_data7E1 = country_df('FootballData/data (7)/E1.csv')\n",
    "df_data7E2 = country_df('FootballData/data (7)/E2.csv')\n",
    "df_data7E3 = country_df('FootballData/data (7)/E3.csv')\n",
    "df_data7EC = country_df('FootballData/data (7)/EC.csv')\n",
    "df_data7F2 = country_df('FootballData/data (7)/F2.csv')\n",
    "df_data7G1 = country_df('FootballData/data (7)/G1.csv')\n",
    "df_data7N1 = country_df('FootballData/data (7)/N1.csv')\n",
    "df_data7P1 = country_df('FootballData/data (7)/P1.csv')\n",
    "df_data7SC0 = country_df('FootballData/data (7)/SC0.csv')\n",
    "df_data7SC1 = country_df('FootballData/data (7)/SC1.csv')\n",
    "df_data7SC2 = country_df('FootballData/data (7)/SC2.csv')\n",
    "df_data7SC3 = country_df('FootballData/data (7)/SC3.csv')\n",
    "df_data7SP2 = country_df('FootballData/data (7)/SP2.csv')\n",
    "df_data7SP1 = country_df('FootballData/data (7)/SP1.csv')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "data = pd.concat([df_france, df_spain, df_england, df_championship, df_england_22, df_spa_22, df_ita,df_E1,df_E2,df_E3,df_EC,df_F2,df_I2,df_dataE0,df_dataE1,df_dataE2,df_dataE3,df_dataEC,df_dataF2,df_dataG1,df_dataN1,df_dataP1,df_dataSC0,df_dataSC1,df_dataSC2,df_dataSC3,df_dataSP1,df_dataSP2,df_dataT1,\n",
    "                  df_data8E0,df_data8E1,df_data8E2,df_data8E3,df_data8EC,df_data8G1,df_data8SC0,df_data8SC1,df_data8SC2,df_data8SC3,df_data8SP1,df_data8T1,\n",
    "                  df_data8E0,df_data7E1,df_data7E2,df_data7E3,df_data7EC,df_data7G1,df_data7SC0,df_data7SC1,df_data7SC2,df_data7SC3,df_data7SP1,df_data7SP2,df_data7P1,df_data7N1,df_data7F2], sort = False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[[\"FTHG\",\"FTAG\",\"B365H\",\"B365D\",\"B365A\",\"FTR\"]]\n",
    "\n",
    "#data['FTR'] = data['FTR'].map({'H':0,'D':1,'A':2})\n",
    "\n",
    "# Create a boolean mask for rows with NaN values\n",
    "mask = data.isnull().any(axis=1)\n",
    "\n",
    "# Delete rows using the mask\n",
    "data = data[~mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the dependent variable class\n",
    "factor = pd.factorize(data['FTR'])\n",
    "data.FTR = factor[0]\n",
    "definitions = factor[1]\n",
    "print(data.FTR.head())\n",
    "print(definitions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting the data into independent and dependent variables\n",
    "X = data.iloc[:,0:5].values\n",
    "y = data.iloc[:,5].values\n",
    "print('The independent features set: ')\n",
    "print(X[:5,:])\n",
    "print('The dependent variable: ')\n",
    "print(y[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data to train and test dataset.\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "X_train = torch.FloatTensor(X_train)\n",
    "X_test = torch.FloatTensor(X_test)\n",
    "y_train = torch.LongTensor(y_train)\n",
    "y_test = torch.LongTensor(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"y_train:\", y_train.shape)\n",
    "print(\"y_test:\", y_test.shape)\n",
    "\n",
    "print(\"xtrain:\", X_train.shape)\n",
    "print(\"ytrain:\", X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "\n",
    "# Define your PyTorch model here\n",
    "class MyModel(torch.nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(MyModel, self).__init__()\n",
    "        # Define your layers here\n",
    "        self.input_layer    = nn.Linear(input_size,256)\n",
    "        self.hidden_layer1  = nn.Linear(256,512)\n",
    "        self.hidden_layer2  = nn.Linear(512,128)\n",
    "        self.hidden_layer3  = nn.Linear(128,8)\n",
    "        self.output_layer   = nn.Linear(8,output_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.4)  # Add this line\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Define your forward pass here\n",
    "        out =  self.dropout(self.relu(self.input_layer(x)))\n",
    "        out =  self.dropout(self.relu(self.hidden_layer1(out)))\n",
    "        out =  self.dropout(self.relu(self.hidden_layer2(out)))\n",
    "        out =  self.dropout(self.relu(self.hidden_layer3(out)))\n",
    "        out =  self.output_layer(out)\n",
    "        out =  self.dropout(out)\n",
    "        return out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size=5\n",
    "output_size =3\n",
    "# Instantiate your model\n",
    "model = MyModel(input_size,output_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    " \n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.003)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import tqdm\n",
    "import numpy as np\n",
    "\n",
    "n_epochs = 100\n",
    "batch_size =1000\n",
    "batches_per_epoch = len(X_train) // batch_size\n",
    "\n",
    "best_acc = - np.inf   # init to negative infinity\n",
    "best_weights = None\n",
    "train_loss_hist = []\n",
    "train_acc_hist = []\n",
    "test_loss_hist = []\n",
    "test_acc_hist = []\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    epoch_loss = []\n",
    "    epoch_acc = []\n",
    "    # set model in training mode and run through each batch\n",
    "    model.train()\n",
    "    with tqdm.trange(batches_per_epoch, unit=\"batch\", mininterval=0) as bar:\n",
    "        bar.set_description(f\"Epoch {epoch}\")\n",
    "        for i in bar:\n",
    "            # take a batch\n",
    "            start = i * batch_size\n",
    "            X_batch = X_train[start:start+batch_size]\n",
    "            y_batch = y_train[start:start+batch_size]\n",
    "            # forward pass\n",
    "            y_pred = model(X_batch)\n",
    "            loss = loss_fn(y_pred, y_batch)\n",
    "            # backward pass\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            # update weights\n",
    "            optimizer.step()\n",
    "            # compute and store metrics\n",
    "            acc = (torch.argmax(y_pred) == torch.argmax(y_batch)).float().mean()\n",
    "            epoch_loss.append(float(loss))\n",
    "            epoch_acc.append(float(acc))\n",
    "            bar.set_postfix(\n",
    "                loss=float(loss),\n",
    "                acc=float(acc)\n",
    "            )\n",
    "    # set model in evaluation mode and run through the test set\n",
    "    model.eval()\n",
    "    y_pred = model(X_test)\n",
    "    ce = loss_fn(y_pred, y_test)\n",
    "    acc = (torch.argmax(y_pred) == torch.argmax(y_test)).float().mean()\n",
    "    ce = float(ce)\n",
    "    acc = float(acc)\n",
    "    train_loss_hist.append(np.mean(epoch_loss))\n",
    "    train_acc_hist.append(np.mean(epoch_acc))\n",
    "    test_loss_hist.append(ce)\n",
    "    test_acc_hist.append(acc)\n",
    "    if acc > best_acc:\n",
    "        best_acc = acc\n",
    "        best_weights = copy.deepcopy(model.state_dict())\n",
    "    print(f\"Epoch {epoch} validation: Cross-entropy={ce}, Accuracy={acc}\")\n",
    "    \n",
    "model.load_state_dict(best_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    " \n",
    "plt.plot(train_loss_hist, label=\"train\")\n",
    "plt.plot(test_loss_hist, label=\"test\")\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"cross entropy\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    " \n",
    "plt.plot(train_acc_hist, label=\"train\")\n",
    "plt.plot(test_acc_hist, label=\"test\")\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your input tensor here\n",
    "# Create a DataFrame with your single row of data\n",
    "single_row = pd.DataFrame({\n",
    "    'FTHG': [2.11],\n",
    "    'FTAG': [3.88],\n",
    "    'B365H': [5.72],\n",
    "    'B365D': [4.02],\n",
    "    'B365A': [1.62]\n",
    "    # Add other features here...\n",
    "})\n",
    "\n",
    "# Convert the DataFrame to a PyTorch tensor\n",
    "input_tensor = torch.tensor(single_row.values).float()\n",
    "\n",
    "# Get the output tensor from your model\n",
    "output = model(input_tensor)\n",
    "\n",
    "# Perform Monte Carlo simulations\n",
    "n_simulations = 100\n",
    "predictions = []\n",
    "noise_std=0.3\n",
    "for i in range(n_simulations):\n",
    "    noisy_output = output + torch.randn_like(output) * noise_std\n",
    "    max_probs, max_indices = torch.max(noisy_output, dim=1)\n",
    "    predictions.append(max_indices.numpy())\n",
    "\n",
    "# Get the most frequent prediction\n",
    "predictions = np.array(predictions)\n",
    "predictions = np.squeeze(predictions)\n",
    "final_prediction = np.bincount(predictions).argmax()\n",
    "final_prediction"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

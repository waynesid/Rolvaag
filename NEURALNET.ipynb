{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the team related datasets into the notebook and save them as dataframes\n",
    "def country_df(csv):\n",
    "  df = pd.read_csv(csv)\n",
    "  df.sort_values('HomeTeam', inplace=True)\n",
    "  df.reset_index(inplace=True)\n",
    "  df.drop(\"index\", axis =1 , inplace=True)\n",
    "\n",
    "  return df\n",
    "\n",
    "df_france = country_df('FootballData/F1.csv')\n",
    "df_spain  = country_df('FootballData/SP1.csv')\n",
    "df_england  = country_df('FootballData/E0.csv')\n",
    "df_championship  = country_df('FootballData/E1.csv')\n",
    "#df_finland  = country_df('/content/drive/MyDrive/FootballData/FIN.csv')\n",
    "#df_germany = country_df('FootballData/D1.csv')\n",
    "df_england_22 = country_df('FootballData/E0_22.csv')\n",
    "df_spa_22 = country_df('FootballData/SP1_22.csv')\n",
    "#df_jpn = country_df('FootballData/JPN.csv')\n",
    "df_ita = country_df('FootballData/I1.csv')\n",
    "df_E1 = country_df('FootballData/E1.csv')\n",
    "df_E2 = country_df('FootballData/E2.csv')\n",
    "df_E3 = country_df('FootballData/E3.csv')\n",
    "df_EC = country_df('FootballData/EC.csv')\n",
    "df_F2 = country_df('FootballData/F2.csv')\n",
    "df_I2 = country_df('FootballData/I2.csv')\n",
    "df_dataE0 = country_df('FootballData/data (9)/E0.csv')\n",
    "df_dataE1 = country_df('FootballData/data (9)/E1.csv')\n",
    "df_dataE2 = country_df('FootballData/data (9)/E2.csv')\n",
    "df_dataE3 = country_df('FootballData/data (9)/E3.csv')\n",
    "df_dataEC = country_df('FootballData/data (9)/EC.csv')\n",
    "df_dataF2 = country_df('FootballData/data (9)/F2.csv')\n",
    "df_dataG1 = country_df('FootballData/data (9)/G1.csv')\n",
    "df_dataN1 = country_df('FootballData/data (9)/N1.csv')\n",
    "df_dataP1 = country_df('FootballData/data (9)/P1.csv')\n",
    "df_dataSC0 = country_df('FootballData/data (9)/SC0.csv')\n",
    "df_dataSC1 = country_df('FootballData/data (9)/SC1.csv')\n",
    "df_dataSC2 = country_df('FootballData/data (9)/SC2.csv')\n",
    "df_dataSC3 = country_df('FootballData/data (9)/SC3.csv')\n",
    "df_dataSP2 = country_df('FootballData/data (9)/SP2.csv')\n",
    "df_dataSP1 = country_df('FootballData/data (9)/SP1.csv')\n",
    "df_dataT1 = country_df('FootballData/data (9)/T1.csv')\n",
    "\n",
    "df_data8E0 = country_df('FootballData/data (8)/E0.csv')\n",
    "df_data8E1 = country_df('FootballData/data (8)/E1.csv')\n",
    "df_data8E2 = country_df('FootballData/data (8)/E2.csv')\n",
    "df_data8E3 = country_df('FootballData/data (8)/E3.csv')\n",
    "df_data8EC = country_df('FootballData/data (8)/EC.csv')\n",
    "#df_data8F2 = country_df('FootballData/data (8)/F2.csv')\n",
    "df_data8G1 = country_df('FootballData/data (8)/G1.csv')\n",
    "#df_data8N1 = country_df('FootballData/data (8)/N1.csv')\n",
    "#df_data8P1 = country_df('FootballData/data (8)/P1.csv')\n",
    "df_data8SC0 = country_df('FootballData/data (8)/SC0.csv')\n",
    "df_data8SC1 = country_df('FootballData/data (8)/SC1.csv')\n",
    "df_data8SC2 = country_df('FootballData/data (8)/SC2.csv')\n",
    "df_data8SC3 = country_df('FootballData/data (8)/SC3.csv')\n",
    "#df_data8SP2 = country_df('FootballData/data (8)/SP2.csv')\n",
    "df_data8SP1 = country_df('FootballData/data (8)/SP1.csv')\n",
    "df_data8T1 = country_df('FootballData/data (8)/T1.csv')\n",
    "df_B1 = country_df('FootballData/B1.csv')\n",
    "\n",
    "\n",
    "\n",
    "data = pd.concat([df_france, df_spain, df_england, df_championship, df_england_22, df_spa_22, df_ita,df_E1,df_E2,df_E3,df_EC,df_F2,df_I2,df_dataE0,df_dataE1,df_dataE2,df_dataE3,df_dataEC,df_dataF2,df_dataG1,df_dataN1,df_dataP1,df_dataSC0,df_dataSC1,df_dataSC2,df_dataSC3,df_dataSP1,df_dataSP2,df_dataT1,\n",
    "                  df_data8E0,df_data8E1,df_data8E2,df_data8E3,df_data8EC,df_data8G1,df_data8SC0,df_data8SC1,df_data8SC2,df_data8SC3,df_data8SP1,df_data8T1], sort = False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15744, 139)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Div             0\n",
       "Date            0\n",
       "HomeTeam        0\n",
       "AwayTeam        0\n",
       "FTHG            0\n",
       "            ...  \n",
       "AvgCAHH     14984\n",
       "AvgCAHA     14984\n",
       "BSH          5823\n",
       "BSD          5823\n",
       "BSA          5823\n",
       "Length: 139, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FTHG</th>\n",
       "      <th>FTAG</th>\n",
       "      <th>HTHG</th>\n",
       "      <th>HTAG</th>\n",
       "      <th>HS</th>\n",
       "      <th>AS</th>\n",
       "      <th>HST</th>\n",
       "      <th>AST</th>\n",
       "      <th>HY</th>\n",
       "      <th>AY</th>\n",
       "      <th>...</th>\n",
       "      <th>B365CAHA</th>\n",
       "      <th>PCAHH</th>\n",
       "      <th>PCAHA</th>\n",
       "      <th>MaxCAHH</th>\n",
       "      <th>MaxCAHA</th>\n",
       "      <th>AvgCAHH</th>\n",
       "      <th>AvgCAHA</th>\n",
       "      <th>BSH</th>\n",
       "      <th>BSD</th>\n",
       "      <th>BSA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>15744.000000</td>\n",
       "      <td>15744.000000</td>\n",
       "      <td>15743.000000</td>\n",
       "      <td>15743.000000</td>\n",
       "      <td>11327.000000</td>\n",
       "      <td>11327.000000</td>\n",
       "      <td>11327.000000</td>\n",
       "      <td>11327.000000</td>\n",
       "      <td>11342.000000</td>\n",
       "      <td>11342.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>759.000000</td>\n",
       "      <td>760.000000</td>\n",
       "      <td>760.000000</td>\n",
       "      <td>760.000000</td>\n",
       "      <td>760.000000</td>\n",
       "      <td>760.000000</td>\n",
       "      <td>760.000000</td>\n",
       "      <td>9921.000000</td>\n",
       "      <td>9921.000000</td>\n",
       "      <td>9921.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.437500</td>\n",
       "      <td>1.100356</td>\n",
       "      <td>0.643079</td>\n",
       "      <td>0.479896</td>\n",
       "      <td>12.011654</td>\n",
       "      <td>9.577911</td>\n",
       "      <td>5.742827</td>\n",
       "      <td>4.544010</td>\n",
       "      <td>1.448774</td>\n",
       "      <td>1.818815</td>\n",
       "      <td>...</td>\n",
       "      <td>1.957036</td>\n",
       "      <td>1.962368</td>\n",
       "      <td>1.967145</td>\n",
       "      <td>2.021408</td>\n",
       "      <td>2.027342</td>\n",
       "      <td>1.936118</td>\n",
       "      <td>1.940961</td>\n",
       "      <td>2.287810</td>\n",
       "      <td>3.413472</td>\n",
       "      <td>3.787174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.219339</td>\n",
       "      <td>1.066113</td>\n",
       "      <td>0.803825</td>\n",
       "      <td>0.689384</td>\n",
       "      <td>4.622596</td>\n",
       "      <td>4.110183</td>\n",
       "      <td>2.974402</td>\n",
       "      <td>2.615035</td>\n",
       "      <td>1.250896</td>\n",
       "      <td>1.364154</td>\n",
       "      <td>...</td>\n",
       "      <td>0.099912</td>\n",
       "      <td>0.104936</td>\n",
       "      <td>0.104870</td>\n",
       "      <td>0.104814</td>\n",
       "      <td>0.109980</td>\n",
       "      <td>0.094286</td>\n",
       "      <td>0.093737</td>\n",
       "      <td>0.989092</td>\n",
       "      <td>0.486010</td>\n",
       "      <td>2.086802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.580000</td>\n",
       "      <td>1.710000</td>\n",
       "      <td>1.610000</td>\n",
       "      <td>1.810000</td>\n",
       "      <td>1.650000</td>\n",
       "      <td>1.730000</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>1.080000</td>\n",
       "      <td>2.620000</td>\n",
       "      <td>1.050000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.880000</td>\n",
       "      <td>1.880000</td>\n",
       "      <td>1.880000</td>\n",
       "      <td>1.940000</td>\n",
       "      <td>1.940000</td>\n",
       "      <td>1.860000</td>\n",
       "      <td>1.860000</td>\n",
       "      <td>1.730000</td>\n",
       "      <td>3.250000</td>\n",
       "      <td>2.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.960000</td>\n",
       "      <td>1.960000</td>\n",
       "      <td>1.960000</td>\n",
       "      <td>2.015000</td>\n",
       "      <td>2.020000</td>\n",
       "      <td>1.935000</td>\n",
       "      <td>1.940000</td>\n",
       "      <td>2.100000</td>\n",
       "      <td>3.250000</td>\n",
       "      <td>3.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.040000</td>\n",
       "      <td>2.040000</td>\n",
       "      <td>2.050000</td>\n",
       "      <td>2.102500</td>\n",
       "      <td>2.110000</td>\n",
       "      <td>2.010000</td>\n",
       "      <td>2.020000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>4.330000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.200000</td>\n",
       "      <td>2.480000</td>\n",
       "      <td>2.270000</td>\n",
       "      <td>2.520000</td>\n",
       "      <td>2.310000</td>\n",
       "      <td>2.420000</td>\n",
       "      <td>2.200000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>23.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 131 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               FTHG          FTAG          HTHG          HTAG            HS  \\\n",
       "count  15744.000000  15744.000000  15743.000000  15743.000000  11327.000000   \n",
       "mean       1.437500      1.100356      0.643079      0.479896     12.011654   \n",
       "std        1.219339      1.066113      0.803825      0.689384      4.622596   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        1.000000      0.000000      0.000000      0.000000      9.000000   \n",
       "50%        1.000000      1.000000      0.000000      0.000000     12.000000   \n",
       "75%        2.000000      2.000000      1.000000      1.000000     15.000000   \n",
       "max        9.000000      9.000000      6.000000      5.000000     44.000000   \n",
       "\n",
       "                 AS           HST           AST            HY            AY  \\\n",
       "count  11327.000000  11327.000000  11327.000000  11342.000000  11342.000000   \n",
       "mean       9.577911      5.742827      4.544010      1.448774      1.818815   \n",
       "std        4.110183      2.974402      2.615035      1.250896      1.364154   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        7.000000      4.000000      3.000000      0.000000      1.000000   \n",
       "50%        9.000000      5.000000      4.000000      1.000000      2.000000   \n",
       "75%       12.000000      7.000000      6.000000      2.000000      3.000000   \n",
       "max       33.000000     24.000000     18.000000      8.000000      9.000000   \n",
       "\n",
       "       ...    B365CAHA       PCAHH       PCAHA     MaxCAHH     MaxCAHA  \\\n",
       "count  ...  759.000000  760.000000  760.000000  760.000000  760.000000   \n",
       "mean   ...    1.957036    1.962368    1.967145    2.021408    2.027342   \n",
       "std    ...    0.099912    0.104936    0.104870    0.104814    0.109980   \n",
       "min    ...    1.580000    1.710000    1.610000    1.810000    1.650000   \n",
       "25%    ...    1.880000    1.880000    1.880000    1.940000    1.940000   \n",
       "50%    ...    1.960000    1.960000    1.960000    2.015000    2.020000   \n",
       "75%    ...    2.040000    2.040000    2.050000    2.102500    2.110000   \n",
       "max    ...    2.200000    2.480000    2.270000    2.520000    2.310000   \n",
       "\n",
       "          AvgCAHH     AvgCAHA          BSH          BSD          BSA  \n",
       "count  760.000000  760.000000  9921.000000  9921.000000  9921.000000  \n",
       "mean     1.936118    1.940961     2.287810     3.413472     3.787174  \n",
       "std      0.094286    0.093737     0.989092     0.486010     2.086802  \n",
       "min      1.730000    1.600000     1.080000     2.620000     1.050000  \n",
       "25%      1.860000    1.860000     1.730000     3.250000     2.600000  \n",
       "50%      1.935000    1.940000     2.100000     3.250000     3.200000  \n",
       "75%      2.010000    2.020000     2.500000     3.500000     4.330000  \n",
       "max      2.420000    2.200000    23.000000     9.000000    23.000000  \n",
       "\n",
       "[8 rows x 131 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[[\"FTHG\",\"FTAG\",\"FTR\",\"B365H\",\"B365D\",\"B365A\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15744, 6)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FTHG</th>\n",
       "      <th>FTAG</th>\n",
       "      <th>FTR</th>\n",
       "      <th>B365H</th>\n",
       "      <th>B365D</th>\n",
       "      <th>B365A</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>A</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.30</td>\n",
       "      <td>1.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>H</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.87</td>\n",
       "      <td>2.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>H</td>\n",
       "      <td>2.2</td>\n",
       "      <td>2.75</td>\n",
       "      <td>3.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>D</td>\n",
       "      <td>1.9</td>\n",
       "      <td>2.87</td>\n",
       "      <td>4.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>H</td>\n",
       "      <td>2.4</td>\n",
       "      <td>3.00</td>\n",
       "      <td>2.70</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   FTHG  FTAG FTR  B365H  B365D  B365A\n",
       "0     1     3   A    5.0   3.30   1.61\n",
       "1     1     0   H    3.0   2.87   2.30\n",
       "2     1     0   H    2.2   2.75   3.40\n",
       "3     0     0   D    1.9   2.87   4.20\n",
       "4     3     1   H    2.4   3.00   2.70"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FTHG      0\n",
       "FTAG      0\n",
       "FTR       0\n",
       "B365H    27\n",
       "B365D    27\n",
       "B365A    27\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FTHG</th>\n",
       "      <th>FTAG</th>\n",
       "      <th>FTR</th>\n",
       "      <th>B365H</th>\n",
       "      <th>B365D</th>\n",
       "      <th>B365A</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>H</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>H</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>H</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>D</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>H</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>H</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>D</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>H</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>H</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>H</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>H</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>461</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>462</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>464</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>D</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>507</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>H</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>546</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>H</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>H</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>D</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>H</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>H</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>D</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     FTHG  FTAG FTR  B365H  B365D  B365A\n",
       "62      2     1   H    NaN    NaN    NaN\n",
       "264     4     0   H    NaN    NaN    NaN\n",
       "139     1     0   H    NaN    NaN    NaN\n",
       "84      2     2   D    NaN    NaN    NaN\n",
       "346     1     2   A    NaN    NaN    NaN\n",
       "384     2     1   H    NaN    NaN    NaN\n",
       "5       4     0   H    NaN    NaN    NaN\n",
       "34      0     0   D    NaN    NaN    NaN\n",
       "96      4     2   H    NaN    NaN    NaN\n",
       "119     3     0   H    NaN    NaN    NaN\n",
       "218     1     0   H    NaN    NaN    NaN\n",
       "294     1     0   H    NaN    NaN    NaN\n",
       "461     1     2   A    NaN    NaN    NaN\n",
       "462     0     3   A    NaN    NaN    NaN\n",
       "464     0     2   A    NaN    NaN    NaN\n",
       "476     0     4   A    NaN    NaN    NaN\n",
       "478     0     5   A    NaN    NaN    NaN\n",
       "479     0     2   A    NaN    NaN    NaN\n",
       "481     1     1   D    NaN    NaN    NaN\n",
       "507     2     0   H    NaN    NaN    NaN\n",
       "546     2     0   H    NaN    NaN    NaN\n",
       "195     1     3   A    NaN    NaN    NaN\n",
       "197     2     1   H    NaN    NaN    NaN\n",
       "212     1     1   D    NaN    NaN    NaN\n",
       "203     3     0   H    NaN    NaN    NaN\n",
       "218     2     0   H    NaN    NaN    NaN\n",
       "239     1     1   D    NaN    NaN    NaN"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.loc[data.isnull().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a boolean mask for rows with NaN values\n",
    "mask = data.isnull().any(axis=1)\n",
    "\n",
    "# Delete rows using the mask\n",
    "data = data[~mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['FTR'] = data['FTR'].map({'H':0,'D':1,'A':2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding .values for the neural network\n",
    "X=data.drop(\"FTR\", axis=1).values\n",
    "Y=data[\"FTR\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15717, 5)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15717,)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "# Scale data to have mean 0 and variance 1 \n",
    "# which is importance for convergence of the neural network\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data to train and test dataset.\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, Y, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.FloatTensor(X_train)\n",
    "X_test = torch.FloatTensor(X_test)\n",
    "y_train = torch.LongTensor(y_train)\n",
    "y_test = torch.LongTensor(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class NeuralNetworkClassificationModel(nn.Module):\n",
    "    def __init__(self,input_dim,output_dim):\n",
    "        super(NeuralNetworkClassificationModel,self).__init__()\n",
    "        self.input_layer    = nn.Linear(input_dim,1024)\n",
    "        self.hidden_layer1  = nn.Linear(1024,512)\n",
    "        self.hidden_layer2  = nn.Linear(512,256)\n",
    "        self.hidden_layer3  = nn.Linear(256,16)\n",
    "        self.output_layer   = nn.Linear(16,output_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.3)  # Add this line\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        out =  self.dropout(self.relu(self.input_layer(x)))\n",
    "        out =  self.dropout(self.relu(self.hidden_layer1(out)))\n",
    "        out =  self.dropout(self.relu(self.hidden_layer2(out)))\n",
    "        out =  self.dropout(self.relu(self.hidden_layer3(out)))\n",
    "        out =  self.output_layer(out)\n",
    "        out =  self.softmax(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim  = 5\n",
    "output_dim = 3\n",
    "model = NeuralNetworkClassificationModel(input_dim,output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# Define batch size.\n",
    "batch_size =1000\n",
    "\n",
    "# Create Tensor datasets.\n",
    "train_data = TensorDataset(X_train, y_train)\n",
    "test_data = TensorDataset(X_test, y_test)\n",
    "\n",
    "# Create DataLoaders.\n",
    "dataloader_train = DataLoader(train_data, shuffle=True, batch_size=batch_size)\n",
    "dataloader_test = DataLoader(test_data, shuffle=True, batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-3\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyperparameters to consider ; momentum=int, nesterov=boolean,decay_rate=(int) learning_rate/epochs -->these are in the optimizer field\n",
    "#adding batch size in training\n",
    "train_losses = []\n",
    "test_losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_network(model, optimizer, criterion, dataloader_train, dataloader_test, num_epochs, train_losses, test_losses):\n",
    "    for epoch in range(num_epochs):\n",
    "        # Training\n",
    "        model.train()\n",
    "        for X_train, y_train in dataloader_train:\n",
    "            # Clear out the gradients from the last step (loss.backward()).\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward feed.\n",
    "            output_train = model(X_train)\n",
    "\n",
    "            # Calculate the loss.\n",
    "            loss_train = criterion(output_train, y_train)\n",
    "\n",
    "            # Backward propagation: calculate gradients.\n",
    "            loss_train.backward()\n",
    "\n",
    "            # Update the weights.\n",
    "            optimizer.step()\n",
    "\n",
    "            # Record the loss.\n",
    "            import numpy as np\n",
    "\n",
    "            # Record the loss.\n",
    "            train_losses = np.append(train_losses, loss_train.item())\n",
    "\n",
    "\n",
    "        # Evaluation\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for X_test, y_test in dataloader_test:\n",
    "                output_test = model(X_test)\n",
    "                loss_test = criterion(output_test, y_test)\n",
    "\n",
    "                # Record the loss.\n",
    "                test_losses = np.append(loss_test, loss_test.item())\n",
    "\n",
    "        if (epoch + 1) % 50 == 0:\n",
    "            print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {np.mean(train_losses):.7f}, Test Loss: {np.mean(test_losses):.7f}\")\n",
    "\n",
    "    return train_losses, test_losses\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/1000, Train Loss: 0.5617177, Test Loss: 0.5514446\n",
      "Epoch 100/1000, Train Loss: 0.5575792, Test Loss: 0.5514446\n",
      "Epoch 150/1000, Train Loss: 0.5561313, Test Loss: 0.5514446\n",
      "Epoch 200/1000, Train Loss: 0.5553834, Test Loss: 0.5514446\n",
      "Epoch 250/1000, Train Loss: 0.5547386, Test Loss: 0.5531929\n",
      "Epoch 300/1000, Train Loss: 0.5543492, Test Loss: 0.5514446\n",
      "Epoch 350/1000, Train Loss: 0.5540459, Test Loss: 0.5514446\n",
      "Epoch 400/1000, Train Loss: 0.5537977, Test Loss: 0.5514446\n",
      "Epoch 450/1000, Train Loss: 0.5536191, Test Loss: 0.5514446\n",
      "Epoch 500/1000, Train Loss: 0.5534606, Test Loss: 0.5514446\n",
      "Epoch 550/1000, Train Loss: 0.5533438, Test Loss: 0.5514446\n",
      "Epoch 600/1000, Train Loss: 0.5532631, Test Loss: 0.5514446\n",
      "Epoch 650/1000, Train Loss: 0.5531834, Test Loss: 0.5514446\n",
      "Epoch 700/1000, Train Loss: 0.5531017, Test Loss: 0.5514446\n",
      "Epoch 750/1000, Train Loss: 0.5530464, Test Loss: 0.5514446\n",
      "Epoch 800/1000, Train Loss: 0.5529808, Test Loss: 0.5514446\n",
      "Epoch 850/1000, Train Loss: 0.5529429, Test Loss: 0.5514446\n",
      "Epoch 900/1000, Train Loss: 0.5528950, Test Loss: 0.5514446\n",
      "Epoch 950/1000, Train Loss: 0.5528452, Test Loss: 0.5514446\n",
      "Epoch 1000/1000, Train Loss: 0.5528098, Test Loss: 0.5514446\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([1.08438957, 1.07103634, 1.0364784 , ..., 0.55250669, 0.55145693,\n",
       "        0.55163139]),\n",
       " array([0.55144465, 0.55144465]))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_network(model, optimizer, criterion, dataloader_train, dataloader_test, num_epochs, train_losses, test_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_train = []\n",
    "predictions_test =  []\n",
    "with torch.no_grad():\n",
    "    predictions_train = model(X_train)\n",
    "    predictions_test = model(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy_multiclass(pred_arr,original_arr):\n",
    "    if len(pred_arr)!=len(original_arr):\n",
    "        return False\n",
    "    pred_arr = pred_arr.numpy()\n",
    "    original_arr = original_arr.numpy()\n",
    "    final_pred= []\n",
    "    # we will get something like this in the pred_arr [32.1680,12.9350,-58.4877]\n",
    "    # so will be taking the index of that argument which has the highest value here 32.1680 which corresponds to 0th index\n",
    "    for i in range(len(pred_arr)):\n",
    "        final_pred.append(np.argmax(pred_arr[i]))\n",
    "    final_pred = np.array(final_pred)\n",
    "    count = 0\n",
    "    #here we are doing a simple comparison between the predicted_arr and the original_arr to get the final accuracy\n",
    "    for i in range(len(original_arr)):\n",
    "        if final_pred[i] == original_arr[i]:\n",
    "            count+=1\n",
    "    return count/len(final_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_acc = get_accuracy_multiclass(predictions_train,y_train)\n",
    "test_acc  = get_accuracy_multiclass(predictions_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 1.0\n",
      "Test Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training Accuracy: {train_acc}\")\n",
    "print(f\"Test Accuracy: {test_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#[\"FTHG\",\"FTAG\",\"HTHG\",\"HTAG\",\"Form\",\"B365H\",\"B365D\",\"B365A\"]\n",
    "X_new = np.array([[1.08,1.08,1.00,1.60,2.54,3.30,2.96]])\n",
    "X_net = torch.FloatTensor(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (1x7 and 5x1024)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[33], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m----> 8\u001b[0m     prediction \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_net\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m   \u001b[38;5;66;03m# prediction = preprocessing.scale(prediction)\u001b[39;00m\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPrediction of Games: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(prediction))\n",
      "File \u001b[1;32mc:\\Users\\USER\\Wayne\\Rolvaag\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\USER\\Wayne\\Rolvaag\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[20], line 14\u001b[0m, in \u001b[0;36mNeuralNetworkClassificationModel.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m,x):\n\u001b[1;32m---> 14\u001b[0m     out \u001b[38;5;241m=\u001b[39m  \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput_layer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m))\n\u001b[0;32m     15\u001b[0m     out \u001b[38;5;241m=\u001b[39m  \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden_layer1(out)))\n\u001b[0;32m     16\u001b[0m     out \u001b[38;5;241m=\u001b[39m  \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden_layer2(out)))\n",
      "File \u001b[1;32mc:\\Users\\USER\\Wayne\\Rolvaag\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\USER\\Wayne\\Rolvaag\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\USER\\Wayne\\Rolvaag\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (1x7 and 5x1024)"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "\n",
    "torch.manual_seed(42)\n",
    "# During inference or evaluation, apply softmax to obtain class probabilities\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    prediction = model(X_net)\n",
    "\n",
    "  # prediction = preprocessing.scale(prediction)\n",
    "\n",
    "    print(\"Prediction of Games: {}\".format(prediction))\n",
    "\n",
    "\n",
    "# Assuming prediction is a 1D tensor with 3 elements\n",
    "prediction_np = prediction.numpy().flatten()\n",
    "\n",
    "# Calculate the differences\n",
    "diff_12 = prediction_np[1] - prediction_np[0]\n",
    "diff_23 = prediction_np[2] - prediction_np[1]\n",
    "diff_31 = prediction_np[0] - prediction_np[2]\n",
    "\n",
    "# Find the maximum and minimum\n",
    "max_val = np.max(prediction_np)\n",
    "min_val = np.min(prediction_np)\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'Difference 1-2': [diff_12],\n",
    "    'Difference 2-3': [diff_23],\n",
    "    'Difference 3-1': [diff_31],\n",
    "    'Maximum': [max_val],\n",
    "    'Minimum': [min_val]\n",
    "})\n",
    "\n",
    "print(df)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pickle\n",
    "\n",
    "# Create Pickle file from the Neural network Model\n",
    "#with open('neuralnet.pickle', 'wb') as dump_var:\n",
    " #   pickle.dump(data, dump_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pickle.dump(model, open('model.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pickled_model = pickle.load(open('model.pkl', 'rb'))\n",
    "#pickled_model(X_net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Rolvaag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
